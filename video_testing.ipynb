{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c154cf6e",
      "metadata": {
        "id": "c154cf6e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "from IPython.display import Video\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc338316",
      "metadata": {
        "id": "dc338316"
      },
      "outputs": [],
      "source": [
        "# Load your trained model.\n",
        "model = load_model('/content/Final_LRCN.keras')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/mean.pkl\", \"rb\") as f:\n",
        "    mean = pickle.load(f)"
      ],
      "metadata": {
        "id": "ItrT64-WHXiW"
      },
      "id": "ItrT64-WHXiW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/std_array.pkl\", \"rb\") as f:\n",
        "    std = pickle.load(f)"
      ],
      "metadata": {
        "id": "PlBP5sJsGO6t"
      },
      "id": "PlBP5sJsGO6t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/class_list1.pkl\", \"rb\") as f:\n",
        "    encoder1 = pickle.load(f)"
      ],
      "metadata": {
        "id": "jkovoy_9R6b-"
      },
      "id": "jkovoy_9R6b-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_url = 'https://www.youtube.com/watch?v=hMTtOjcOFbQ'"
      ],
      "metadata": {
        "id": "RDYlmJfbNg_6"
      },
      "id": "RDYlmJfbNg_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "793ede93",
      "metadata": {
        "id": "793ede93"
      },
      "outputs": [],
      "source": [
        "# Define parameters.\n",
        "SEQUENCE_LENGTH = 25\n",
        "IMAGE_WIDTH = 112\n",
        "IMAGE_HEIGHT = 112\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yt_dlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ThVmiNvT_ud",
        "outputId": "13be4456-35bd-4092-98bb-03e058099425"
      },
      "id": "2ThVmiNvT_ud",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2025.3.31-py3-none-any.whl.metadata (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yt_dlp-2025.3.31-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yt_dlp\n",
            "Successfully installed yt_dlp-2025.3.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CLASS_LIST = ['PushUps', 'PlayingGuitar', 'HighJump', 'RopeClimbing', 'PullUps', 'PoleVault', 'Kayaking', 'Mixing']\n",
        "# CLASS_LIST = ['BaseballPitch', 'BenchPress', 'Billiards', 'BreastStroke', 'PlayingPiano', 'Drumming', 'Fencing']\n",
        "# my_classes = ['JugglingBalls', 'Swing', 'RockClimbingIndoor','HighJump', 'Skijet', 'SkateBoarding', 'MilitaryParade']"
      ],
      "metadata": {
        "id": "LvxtTHJpWe5G"
      },
      "id": "LvxtTHJpWe5G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Downloading the youtube video\n"
      ],
      "metadata": {
        "id": "LqKPyDI1Mdjl"
      },
      "id": "LqKPyDI1Mdjl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a5371a",
      "metadata": {
        "id": "55a5371a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import yt_dlp\n",
        "\n",
        "def download_youtube_video(youtube_video_url, output_directory):\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    # Get the next available sequential filename\n",
        "    existing_files = os.listdir(output_directory)\n",
        "    video_files = sorted([f for f in existing_files if f.startswith(\"vid\") and f.endswith((\".mp4\", \".mkv\", \".webm\"))])\n",
        "\n",
        "    if video_files:\n",
        "        # Extract the largest sequence number\n",
        "        last_seq = max(int(re.search(r'\\d+', f).group()) for f in video_files)\n",
        "        new_seq = last_seq + 1\n",
        "    else:\n",
        "        new_seq = 1\n",
        "\n",
        "    # Format the new filename as vidXX (e.g., vid01, vid02)\n",
        "    new_filename = f\"vid{new_seq:02d}\"\n",
        "\n",
        "    # Configure yt-dlp options\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo+bestaudio/best',\n",
        "        'outtmpl': f'{output_directory}/{new_filename}.%(ext)s',\n",
        "    }\n",
        "\n",
        "    # Download the video\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        info_dict = ydl.extract_info(youtube_video_url, download=True)\n",
        "        ext = info_dict.get('ext', 'mp4')  # Get extension, default to mp4 if not available\n",
        "\n",
        "    # Return the file path and new filename\n",
        "    file_path = os.path.join(output_directory, f\"{new_filename}.{ext}\")\n",
        "    return file_path, new_filename\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "-zgbUp1CaF29"
      },
      "id": "-zgbUp1CaF29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder1.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsJQzr21-JyS",
        "outputId": "f7b7f5a8-5fd1-497d-e07f-a5c0c4392475"
      },
      "id": "UsJQzr21-JyS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BaseballPitch' 'BreastStroke' 'Drumming' 'MilitaryParade' 'PlayingPiano'\n",
            " 'SkateBoarding' 'Skijet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on video"
      ],
      "metadata": {
        "id": "lUHkHluHPowg"
      },
      "id": "lUHkHluHPowg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a315905",
      "metadata": {
        "id": "4a315905"
      },
      "outputs": [],
      "source": [
        "# Function to perform frame-by-frame action recognition on the video.\n",
        "def predict_on_video(input_video_path, output_video_path, model, SEQUENCE_LENGTH):\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc('M','P','4','V')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frames_buffer = deque(maxlen=SEQUENCE_LENGTH)\n",
        "    predicted_class_name = ''\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "\n",
        "\n",
        "    # while True:\n",
        "    #     ret, frame = cap.read()\n",
        "    #     if not ret:\n",
        "    #         break\n",
        "\n",
        "        # Preprocess the frame.\n",
        "        frame_resized = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "        frame_norm = frame_resized / 255.0\n",
        "        frames_buffer.append(frame_norm)\n",
        "\n",
        "        # Once we have a full sequence, predict.\n",
        "        if len(frames_buffer) == SEQUENCE_LENGTH:\n",
        "            # sequence = np.array(frames_buffer)  # shape: (SEQUENCE_LENGTH, 112, 112, 3)\n",
        "\n",
        "            frames_buffer -= mean\n",
        "            frames_buffer /= std\n",
        "            sequence = np.expand_dims(frames_buffer, axis=0)  # shape: (1, SEQUENCE_LENGTH, 112, 112, 3)\n",
        "            prediction = model.predict(sequence)[0]\n",
        "            predicted_label = np.argmax(prediction)\n",
        "            # predicted_class_name = CLASS_LIST[predicted_label]\n",
        "            predicted_class_name = encoder1.inverse_transform([predicted_label])[0]\n",
        "\n",
        "            # Annotate the current frame with the predicted class.\n",
        "            cv2.putText(frame, f'Predicted: {predicted_class_name}', (10, 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            cv2_imshow(frame)\n",
        "            print(f'Action Predicted: {predicted_class_name}\\n')\n",
        "\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9aeeb05",
      "metadata": {
        "id": "a9aeeb05"
      },
      "outputs": [],
      "source": [
        "# Function to perform a single action prediction (using SEQUENCE_LENGTH frames sampled from the video).\n",
        "def predict_single_action(video_file_path, SEQUENCE_LENGTH):\n",
        "    cap = cv2.VideoCapture(video_file_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video file.\")\n",
        "        return\n",
        "\n",
        "    frames_list = []\n",
        "    video_frames_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    skip_frames_window = max(int(video_frames_count / SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "        normalized_frame = resized_frame / 255.0\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "\n",
        "\n",
        "    if len(frames_list) != SEQUENCE_LENGTH:\n",
        "        print(\"Warning: Not enough frames for a full sequence.\")\n",
        "        return\n",
        "\n",
        "    frames_list -= mean\n",
        "    frames_list /= std\n",
        "    sequence = np.expand_dims(np.array(frames_list), axis=0)\n",
        "    prediction = model.predict(sequence)[0]\n",
        "    predicted_index = np.argmax(prediction)\n",
        "    # predicted_class_name = CLASS_LIST[predicted_index]\n",
        "    # predicted_class_name = index_to_label[predicted_index]\n",
        "    predicted_class_name = encoder1.inverse_transform([predicted_index])[0]\n",
        "    confidence = prediction[predicted_index]\n",
        "    print(f'Action Predicted: {predicted_class_name}\\nConfidence: {confidence}')\n",
        "\n",
        "    cap.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c1a303",
      "metadata": {
        "id": "67c1a303"
      },
      "outputs": [],
      "source": [
        "test_videos_directory = 'test_videos'\n",
        "os.makedirs(test_videos_directory, exist_ok=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b7d2e6",
      "metadata": {
        "id": "44b7d2e6",
        "outputId": "ebf900cb-0a8d-400e-e71f-8e6d3c99f83f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=hMTtOjcOFbQ\n",
            "[youtube] hMTtOjcOFbQ: Downloading webpage\n",
            "[youtube] hMTtOjcOFbQ: Downloading tv client config\n",
            "[youtube] hMTtOjcOFbQ: Downloading player 73381ccc-main\n",
            "[youtube] hMTtOjcOFbQ: Downloading tv player API JSON\n",
            "[youtube] hMTtOjcOFbQ: Downloading ios player API JSON\n",
            "[youtube] hMTtOjcOFbQ: Downloading m3u8 information\n",
            "[info] hMTtOjcOFbQ: Downloading 1 format(s): 303+251\n",
            "[download] Destination: test_videos/vid01.f303.webm\n",
            "[download] 100% of   14.72MiB in 00:00:00 at 32.65MiB/s  \n",
            "[download] Destination: test_videos/vid01.f251.webm\n",
            "[download] 100% of  382.48KiB in 00:00:00 at 5.37MiB/s   \n",
            "[Merger] Merging formats into \"test_videos/vid01.webm\"\n",
            "Deleting original file test_videos/vid01.f251.webm (pass -k to keep)\n",
            "Deleting original file test_videos/vid01.f303.webm (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "# Download a YouTube video. (You can change the URL as needed.)\n",
        "\n",
        "input_video_path, safe_title = download_youtube_video(youtube_url, test_videos_directory)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_extraction(video_path):\n",
        "    frames_list = []\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    skip_frames_window = max(int(video_frames_count/25), 1)\n",
        "    for frame_counter in range(25):\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
        "        succes, frame = video_reader.read()\n",
        "        if not succes:\n",
        "            break\n",
        "        frames_list.append(frame)\n",
        "    video_reader.release()\n",
        "\n",
        "    return frames_list"
      ],
      "metadata": {
        "id": "_i6LFlM0H_Hg"
      },
      "id": "_i6LFlM0H_Hg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfdc2499",
      "metadata": {
        "id": "cfdc2499",
        "outputId": "d9b6331a-d8c5-43b6-f8d3-7a6a66518beb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded video path: test_videos/vid01.webm\n",
            "Files in directory: ['vid01.webm']\n",
            "Output video path: test_videos/vid01-Output-SeqLen25.mp4\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "Action Predicted: Skijet\n",
            "Confidence: 0.6569247841835022\n"
          ]
        }
      ],
      "source": [
        "if input_video_path is None:\n",
        "    print(\"Error: Video download failed or file not found.\")\n",
        "else:\n",
        "    print(f\"Downloaded video path: {input_video_path}\")\n",
        "    print(\"Files in directory:\", os.listdir(test_videos_directory))\n",
        "\n",
        "    # Construct the output video path.\n",
        "    output_video_path = os.path.join(test_videos_directory, f\"{safe_title}-Output-SeqLen{SEQUENCE_LENGTH}.mp4\")\n",
        "    print(\"Output video path:\", output_video_path)\n",
        "\n",
        "    # Perform single action prediction on the downloaded video.\n",
        "    predict_single_action(input_video_path, SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079768dc",
      "metadata": {
        "id": "079768dc",
        "outputId": "ff2cf67b-9917-4b76-db90-619afc3cdcf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [],
      "source": [
        "if input_video_path is None:\n",
        "    print(\"Error: Video download failed or file not found.\")\n",
        "else:\n",
        "    print(f\"Downloaded video path: {input_video_path}\")\n",
        "    print(\"Files in directory:\", os.listdir(test_videos_directory))\n",
        "\n",
        "    # Construct the output video path.\n",
        "    output_video_path = os.path.join(test_videos_directory, f\"{safe_title}-Output-SeqLen{SEQUENCE_LENGTH}.mp4\")\n",
        "    print(\"Output video path:\", output_video_path)\n",
        "\n",
        "    # Run continuous prediction on the video.\n",
        "    predict_on_video(input_video_path, output_video_path, model, SEQUENCE_LENGTH)\n",
        "\n",
        "    # Display the output video in the notebook.\n",
        "    from IPython.display import Video\n",
        "    Video(output_video_path, embed=True)\n",
        "\n",
        "\n",
        "    # # Perform single action prediction on the downloaded video.\n",
        "    # predict_single_action(input_video_path, SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "buiFTSQQOIjj"
      },
      "id": "buiFTSQQOIjj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for my rough work"
      ],
      "metadata": {
        "id": "gm6_1P_bOT1B"
      },
      "id": "gm6_1P_bOT1B"
    },
    {
      "cell_type": "code",
      "source": [
        "def Human_activity_prediction(video_path , mean , std):\n",
        "    frames = frames_extraction(video_path)\n",
        "    if len(frames) != 25:\n",
        "        raise ValueError(f\"Expected {25} frames but got {len(frames)} frames from the video.\")\n",
        "    preprocessed_frames = []\n",
        "    for frame in frames:\n",
        "        resized_frame = cv2.resize(frame, (112, 112))\n",
        "        preprocessed_frames.append(resized_frame)\n",
        "\n",
        "    preprocessed_frames= (np.array(preprocessed_frames)).astype(np.float32)\n",
        "    preprocessed_frames -= mean\n",
        "    preprocessed_frames /= std\n",
        "\n",
        "\n",
        "    preprocessed_frames = np.expand_dims(preprocessed_frames, axis=0)\n",
        "\n",
        "    predicted_probabilities = model.predict(preprocessed_frames)[0]\n",
        "    print(predicted_probabilities)\n",
        "    predicted_label = np.argmax(predicted_probabilities)\n",
        "    predicted_class = encoder1.inverse_transform([predicted_label])[0]\n",
        "\n",
        "    print(predicted_class)"
      ],
      "metadata": {
        "id": "uZHTt-huFOqq"
      },
      "id": "uZHTt-huFOqq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Human_activity_prediction(input_video_path,mean,std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyDmKsL8FRh1",
        "outputId": "0bd912ae-78fa-48a5-9948-40d01c2afd4a"
      },
      "id": "iyDmKsL8FRh1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "[0.03632772 0.00226159 0.29508966 0.63694936 0.02332744 0.00348251\n",
            " 0.00256167]\n",
            "MilitaryParade\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (tf-env)",
      "language": "python",
      "name": "tf-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}